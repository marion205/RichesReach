"""
Django settings for richesreach project.
Generated by 'django-admin startproject' using Django 4.2.1.
For more information on this file, see
https://docs.djangoproject.com/en/4.2/topics/settings/
For the full list of settings and their values, see
https://docs.djangoproject.com/en/4.2/ref/settings/
"""
from pathlib import Path
import os
from datetime import timedelta
import environ
# Load environment variables from .env file
env = environ.Env()
environ.Env.read_env()

# Read GRAPHQL_MODE early and log it
GRAPHQL_MODE = os.getenv("GRAPHQL_MODE", "standard").lower()
print(f"[BOOT] GRAPHQL_MODE={GRAPHQL_MODE}", flush=True)
# Build paths inside the project like this: BASE_DIR / 'subdir'.
BASE_DIR = Path(__file__).resolve().parent.parent
# Quick-start development settings - unsuitable for production
# See https://docs.djangoproject.com/en/4.2/howto/deployment/checklist/
# SECURITY WARNING: keep the secret key used in production secret!
SECRET_KEY = 'django-insecure-wk_qy339*l)1xg=(f6_e@9+d7sgi7%#0t!e17a3nkeu&p#@zq9'
# SECURITY WARNING: don't run with debug turned on in production!
DEBUG = os.getenv('DEBUG', 'True').lower() == 'true'
# Production Security Settings
if DEBUG:
    ALLOWED_HOSTS = ["*"]  # dev only - includes current LAN IP
    CORS_ALLOW_ALL_ORIGINS = True
    CORS_ALLOW_CREDENTIALS = True
    # CSRF settings for development
    CSRF_TRUSTED_ORIGINS = [
        "http://172.20.10.8:8000",
        "http://localhost:8000", 
        "http://127.0.0.1:8000",
        "http://192.168.1.151:8000"
    ]
else:
    # Production settings
    ALLOWED_HOSTS = os.getenv('ALLOWED_HOSTS', 'app.richesreach.net,localhost').split(',')
    CORS_ALLOW_ALL_ORIGINS = True
    CORS_ALLOWED_ORIGINS = os.getenv('CORS_ALLOWED_ORIGINS', '').split(',') if os.getenv('CORS_ALLOWED_ORIGINS') else []
    CORS_ALLOW_CREDENTIALS = os.getenv('CORS_ALLOW_CREDENTIALS', 'True').lower() == 'true'
    
    # Security Headers
    SECURE_SSL_REDIRECT = os.getenv('SECURE_SSL_REDIRECT', 'False').lower() == 'true'
    SECURE_HSTS_SECONDS = int(os.getenv('SECURE_HSTS_SECONDS', '0'))
    SECURE_HSTS_INCLUDE_SUBDOMAINS = os.getenv('SECURE_HSTS_INCLUDE_SUBDOMAINS', 'False').lower() == 'true'
    SECURE_HSTS_PRELOAD = os.getenv('SECURE_HSTS_PRELOAD', 'False').lower() == 'true'
    SECURE_CONTENT_TYPE_NOSNIFF = os.getenv('SECURE_CONTENT_TYPE_NOSNIFF', 'True').lower() == 'true'
    SECURE_BROWSER_XSS_FILTER = os.getenv('SECURE_BROWSER_XSS_FILTER', 'True').lower() == 'true'
    X_FRAME_OPTIONS = os.getenv('X_FRAME_OPTIONS', 'DENY')
# Frontend URL for email links
FRONTEND_URL = os.getenv('FRONTEND_URL', 'http://localhost:3000')
# Application definition
INSTALLED_APPS = [
    'django.contrib.admin',
    'django.contrib.auth',
    'django.contrib.contenttypes',
    'django.contrib.sessions',
    'django.contrib.messages',
    'django.contrib.staticfiles',
    'rest_framework',
    'corsheaders',
    'channels',
    'core',
    'graphene_django',
    'gql',  # Add our new GQL app
    'django_celery_results',
    # 'marketdata',  # New market data microservice - temporarily disabled due to migration issues
]

# Optional safety while transitioning
try:
    import channels  # noqa
    if 'channels' not in INSTALLED_APPS:
        INSTALLED_APPS.append('channels')
except ImportError:
    pass
MIDDLEWARE = [
    'corsheaders.middleware.CorsMiddleware',
    'django.middleware.security.SecurityMiddleware',
    'core.middleware.rate_limit.RateLimitMiddleware',
    'django.contrib.sessions.middleware.SessionMiddleware',
    'django.middleware.common.CommonMiddleware',
    'django.middleware.csrf.CsrfViewMiddleware',
    'django.contrib.auth.middleware.AuthenticationMiddleware',
    'django.contrib.messages.middleware.MessageMiddleware',
    'django.middleware.clickjacking.XFrameOptionsMiddleware',
    # Production middleware
    'core.middleware.PerformanceMiddleware',
    'core.middleware.SecurityHeadersMiddleware',
    'core.middleware.RequestLoggingMiddleware',
]
ROOT_URLCONF = 'richesreach.urls'
TEMPLATES = [
{
'BACKEND': 'django.template.backends.django.DjangoTemplates',
'DIRS': [],
'APP_DIRS': True,
'OPTIONS': {
'context_processors': [
'django.template.context_processors.debug',
'django.template.context_processors.request',
'django.contrib.auth.context_processors.auth',
'django.contrib.messages.context_processors.messages',
],
},
},
]
WSGI_APPLICATION = 'richesreach.wsgi.application'
ASGI_APPLICATION = 'richesreach.asgi.application'
# Database
# https://docs.djangoproject.com/en/4.2/ref/settings/#databases

if GRAPHQL_MODE == "simple":
    # Only allow simple mode if explicitly enabled (not in production)
    if os.getenv("SIMPLE_MODE", "false").lower() != "true":
        raise RuntimeError("Simple mode is disabled in production. Set SIMPLE_MODE=true to enable.")
    
    # Do NOT require Postgres just to boot the app
    # Use a throwaway SQLite file so multiple gunicorn workers don't crash on :memory:
    DATABASES = {
        "default": {
            "ENGINE": "django.db.backends.sqlite3",
            "NAME": "/tmp/simple.sqlite3",
        }
    }

    # Make sure migrations don't run / aren't required in this mode
    class _DisableMigrations(dict):
        def __contains__(self, item): return True
        def __getitem__(self, item): return None
    MIGRATION_MODULES = _DisableMigrations()

    # Keep caches lightweight
    CACHES = {
        "default": {
            "BACKEND": "django.core.cache.backends.locmem.LocMemCache",
            "LOCATION": "simple-mode",
        }
    }

    print(f"[BOOT] Using SQLite database for simple mode", flush=True)

else:
    # Production / standard mode - enforce PostgreSQL with SSL
    import urllib.parse as _urlparse

    def _env(name, default=None):
        v = os.getenv(name, default)
        return v

    def _req(name):
        v = os.getenv(name)
        if not v:
            raise RuntimeError(f"Missing required env var: {name}")
        return v

    # Accept DATABASE_URL (postgres://) or PG*/POSTGRES*/DJANGO_DB_* variants.
    def _db_cfg():
        url = _env("DATABASE_URL")
        if url:
            parsed = _urlparse.urlparse(url)
            return {
                "ENGINE": "django.db.backends.postgresql",
                "NAME": parsed.path.lstrip("/") or "postgres",
                "USER": parsed.username,
                "PASSWORD": parsed.password,
                "HOST": parsed.hostname,
                "PORT": parsed.port or "5432",
                "OPTIONS": {"sslmode": _env("SSLMODE", "require")},
            }

        # Normalize keys from multiple naming conventions
        def pick(*names, default=None, required=False):
            for n in names:
                v = os.getenv(n)
                if v:
                    return v
            if required:
                raise RuntimeError(f"No production database configuration found. "
                                   f"Set PG*/POSTGRES*/DJANGO_DB_* or DATABASE_URL.")
            return default

        host = pick("PGHOST","POSTGRES_HOST","DJANGO_DB_HOST", required=True)
        port = pick("PGPORT","POSTGRES_PORT","DJANGO_DB_PORT", default="5432")
        user = pick("PGUSER","POSTGRES_USER","DJANGO_DB_USER", required=True)
        pwd  = pick("PGPASSWORD","POSTGRES_PASSWORD","DJANGO_DB_PASSWORD", required=True)
        name = pick("PGDATABASE","POSTGRES_DB","DJANGO_DB_NAME", required=True)
        sslm = pick("SSLMODE","DJANGO_DB_SSLMODE", default="require")

        return {
            "ENGINE": "django.db.backends.postgresql",
            "NAME": name, "USER": user, "PASSWORD": pwd,
            "HOST": host, "PORT": port,
            "OPTIONS": {"sslmode": sslm},
        }

    DATABASES = {"default": _db_cfg()}

    # Kill SQLite fallback in prod
    if DATABASES["default"]["ENGINE"] != "django.db.backends.postgresql":
        raise RuntimeError("Production must use PostgreSQL")

    # Log database engine for debugging
    import logging
    logging.getLogger(__name__).warning("DB_ENGINE=%s, DB_NAME=%s", DATABASES["default"]["ENGINE"], DATABASES["default"]["NAME"])
# Email Configuration
EMAIL_BACKEND = 'django.core.mail.backends.smtp.EmailBackend'
EMAIL_HOST = os.getenv('EMAIL_HOST', 'smtp.gmail.com')
EMAIL_PORT = int(os.getenv('EMAIL_PORT', '587'))
EMAIL_USE_TLS = os.getenv('EMAIL_USE_TLS', 'True').lower() == 'true'
EMAIL_USE_SSL = False # Disable SSL for local development
EMAIL_SSL_CERTFILE = '' # No SSL certificate file
EMAIL_SSL_KEYFILE = '' # No SSL key file
EMAIL_SSL_CHECK_HOSTNAME = False # Disable hostname verification
EMAIL_HOST_USER = os.getenv('EMAIL_HOST_USER', '')
EMAIL_HOST_PASSWORD = os.getenv('EMAIL_HOST_PASSWORD', '')
DEFAULT_FROM_EMAIL = os.getenv('DEFAULT_FROM_EMAIL', 'noreply@richesreach.com')
# Cache Configuration (for rate limiting and tokens) - set above based on mode
# Password validation
# https://docs.djangoproject.com/en/4.2/ref/settings/#auth-password-validators
AUTH_PASSWORD_VALIDATORS = [
{
'NAME': 'django.contrib.auth.password_validation.UserAttributeSimilarityValidator',
},
{
'NAME': 'django.contrib.auth.password_validation.MinimumLengthValidator',
},
{
'NAME': 'django.contrib.auth.password_validation.CommonPasswordValidator',
},
{
'NAME': 'django.contrib.auth.password_validation.NumericPasswordValidator',
},
]
# Internationalization
# https://docs.djangoproject.com/en/4.2/topics/i18n/
LANGUAGE_CODE = 'en-us'
TIME_ZONE = 'UTC'
USE_I18N = True
USE_TZ = True
# Static files (CSS, JavaScript, Images)
# https://docs.djangoproject.com/en/4.2/howto/static-files/
STATIC_URL = '/static/'
STATIC_ROOT = os.environ.get('STATIC_ROOT', os.path.join(BASE_DIR, 'staticfiles'))

# Default primary key field type
# https://docs.djangoproject.com/en/4.2/ref/settings/#default-auto-field
DEFAULT_AUTO_FIELD = 'django.db.models.BigAutoField'

# Container-Native Logging Configuration - STDOUT/STDERR only
LOG_LEVEL = os.getenv("DJANGO_LOG_LEVEL", "INFO")

LOGGING = {
    "version": 1,
    "disable_existing_loggers": False,
    "formatters": {
        "standard": {"format": "%(asctime)s %(levelname)s %(name)s: %(message)s"},
    },
    "handlers": {
        "console": {
            "class": "logging.StreamHandler",
            "formatter": "standard",
            "level": LOG_LEVEL,
        },
    },
    "root": {"handlers": ["console"], "level": LOG_LEVEL},
    "loggers": {
        "django": {"handlers": ["console"], "level": LOG_LEVEL, "propagate": False},
        "core": {"handlers": ["console"], "level": LOG_LEVEL, "propagate": False},
        # Optional: quiet noisy libraries
        "boto3": {"handlers": ["console"], "level": "WARNING", "propagate": False},
        "botocore": {"handlers": ["console"], "level": "WARNING", "propagate": False},
        "urllib3": {"handlers": ["console"], "level": "WARNING", "propagate": False},
    },
}
CORS_ALLOW_ALL_ORIGINS = True # For dev only

# AAVE/DeFi Configuration
RPC_URL = "https://eth-sepolia.g.alchemy.com/v2/demo"  # Demo RPC for testing
AAVE_POOL_ADDRESS = "0x6Ae43d3271ff6888e7Fc43Fd7321a503ff738951"  # Sepolia AAVE Pool
CHAINLINK_USDC_USD_FEED = "0x5f4eC3Df9cbd43714FE2740f5E3616155c5b8419"  # Mainnet feed for demo
# GRAPHENE configuration moved to the bottom of the file
AUTH_USER_MODEL = "core.User"
# Authentication backends
AUTHENTICATION_BACKENDS = [
'graphql_jwt.backends.JSONWebTokenBackend',
'django.contrib.auth.backends.ModelBackend',
]

# JWT Configuration
GRAPHQL_JWT = {
    'JWT_ALGORITHM': 'HS256',
    'JWT_SECRET_KEY': SECRET_KEY,
    'JWT_EXPIRATION_DELTA': timedelta(minutes=60),
    'JWT_REFRESH_EXPIRATION_DELTA': timedelta(days=7),
    'JWT_VERIFY_EXPIRATION': True,
    'JWT_LEEWAY': 0,
    'JWT_AUTH_HEADER_PREFIX': 'Bearer',
    'JWT_AUTH_COOKIE': None,
}
# Market Data Configuration
REDIS_URL = os.getenv('REDIS_URL', 'redis://localhost:6379/0')
POLYGON_API_KEY = os.getenv('POLYGON_API_KEY')  # No default - must be set via environment
FINNHUB_API_KEY = os.getenv('FINNHUB_API_KEY')  # No default - must be set via environment

# OpenAI Configuration - Production-Ready with Environment Separation
USE_OPENAI = os.getenv('USE_OPENAI', 'false').lower() == 'true'  # Feature flag
OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')  # No default - must be explicitly set
OPENAI_MODEL = os.getenv('OPENAI_MODEL', 'gpt-5o-mini')  # Primary model - GPT-5o-mini
OPENAI_MAX_TOKENS = int(os.getenv('OPENAI_MAX_TOKENS', '1200'))  # Optimized token count
OPENAI_TIMEOUT_MS = int(os.getenv('OPENAI_TIMEOUT_MS', '12000'))  # 12 second timeout
OPENAI_ENABLE_FALLBACK = os.getenv('OPENAI_ENABLE_FALLBACK', 'true').lower() == 'true'  # Safety net

# Environment-specific API keys (recommended for production)
OPENAI_API_KEY_STAGING = os.getenv('OPENAI_API_KEY_STAGING')
OPENAI_API_KEY_PROD = os.getenv('OPENAI_API_KEY_PROD')

# Auto-select API key based on environment
if USE_OPENAI:
    if DEBUG:  # Development/Staging
        OPENAI_API_KEY = OPENAI_API_KEY_STAGING or OPENAI_API_KEY
        print("INFO: Using OpenAI API key for STAGING/DEVELOPMENT")
    else:  # Production
        OPENAI_API_KEY = OPENAI_API_KEY_PROD or OPENAI_API_KEY
        print("INFO: Using OpenAI API key for PRODUCTION")
    
    if not OPENAI_API_KEY:
        print("WARNING: USE_OPENAI=true but no API key found. Disabling OpenAI.")
        USE_OPENAI = False
else:
    print("INFO: OpenAI disabled via USE_OPENAI flag. Using mock/fallback mode.")

# Yodlee Configuration
USE_YODLEE = os.getenv('USE_YODLEE', 'false').lower() == 'true'
YODLEE_ENV = os.getenv('YODLEE_ENV', 'sandbox')
YODLEE_BASE_URL = os.getenv('YODLEE_BASE_URL', 'https://sandbox.api.yodlee.com/ysl')
YODLEE_CLIENT_ID = os.getenv('YODLEE_CLIENT_ID', '')
YODLEE_SECRET = os.getenv('YODLEE_SECRET', '')
YODLEE_FASTLINK_URL = os.getenv('YODLEE_FASTLINK_URL', 'https://sandbox.fastlink2.yodlee.com/apps')
YODLEE_LOGIN_NAME = os.getenv('YODLEE_LOGIN_NAME', '')

# Log Yodlee configuration status
if USE_YODLEE:
    if not all([YODLEE_CLIENT_ID, YODLEE_SECRET, YODLEE_LOGIN_NAME]):
        print("WARNING: USE_YODLEE=true but missing required credentials. Disabling Yodlee.")
        USE_YODLEE = False
    else:
        print(f"INFO: Yodlee enabled - Environment: {YODLEE_ENV}")
else:
    print("INFO: Yodlee disabled via USE_YODLEE flag. Using mock bank linking.")

# SBLOC Configuration
USE_SBLOC_MOCK = bool(os.getenv("USE_SBLOC_MOCK", "true").lower() == "true")
SBLOC_STATUS_ADVANCE_SECONDS = int(os.getenv("SBLOC_STATUS_ADVANCE_SECONDS", "30"))

# SBLOC Aggregator Configuration (for production)
USE_SBLOC_AGGREGATOR = os.getenv('USE_SBLOC_AGGREGATOR', 'false').lower() == 'true'
SBLOC_AGGREGATOR_BASE_URL = os.getenv('SBLOC_AGGREGATOR_BASE_URL', 'https://api.sbloc-aggregator.com')
SBLOC_AGGREGATOR_API_KEY = os.getenv('SBLOC_AGGREGATOR_API_KEY', '')
SBLOC_WEBHOOK_SECRET = os.getenv('SBLOC_WEBHOOK_SECRET', '')
SBLOC_REDIRECT_URI = os.getenv('SBLOC_REDIRECT_URI', 'https://app.richesreach.net/sbloc/callback')

# Log SBLOC configuration status
if USE_SBLOC_MOCK:
    print(f"INFO: SBLOC Mock enabled - Status advance every {SBLOC_STATUS_ADVANCE_SECONDS}s")
elif USE_SBLOC_AGGREGATOR:
    if not all([SBLOC_AGGREGATOR_API_KEY, SBLOC_WEBHOOK_SECRET]):
        print("WARNING: USE_SBLOC_AGGREGATOR=true but missing required credentials. Disabling SBLOC.")
        USE_SBLOC_AGGREGATOR = False
    else:
        print(f"INFO: SBLOC Aggregator enabled - Base URL: {SBLOC_AGGREGATOR_BASE_URL}")
else:
    print("INFO: SBLOC disabled. Set USE_SBLOC_MOCK=true for development.")

# ML Service Configuration
ML_SERVICE_CONFIG = {
    'ENABLED': os.getenv('ML_SERVICE_ENABLED', 'True').lower() == 'true',
    'MODEL_PATH': os.getenv('ML_MODEL_PATH', 'backend/ml_models/'),
    'CACHE_TIMEOUT': int(os.getenv('ML_CACHE_TIMEOUT', '3600')),  # 1 hour
    'BATCH_SIZE': int(os.getenv('ML_BATCH_SIZE', '100')),
    'MAX_CONCURRENT_REQUESTS': int(os.getenv('ML_MAX_CONCURRENT', '10')),
    'FALLBACK_TO_RULES': os.getenv('ML_FALLBACK_TO_RULES', 'True').lower() == 'true',
    'LOG_LEVEL': os.getenv('ML_LOG_LEVEL', 'INFO'),
    'ENABLE_OPTIMIZATION': os.getenv('ML_ENABLE_OPTIMIZATION', 'True').lower() == 'true',
    'ENABLE_RISK_METRICS': os.getenv('ML_ENABLE_RISK_METRICS', 'True').lower() == 'true',
    'ENABLE_TRANSACTION_COSTS': os.getenv('ML_ENABLE_TRANSACTION_COSTS', 'True').lower() == 'true',
}

# Point-in-Time Data Configuration
POINT_IN_TIME_CONFIG = {
    'ENABLED': os.getenv('PIT_DATA_ENABLED', 'True').lower() == 'true',
    'SNAPSHOT_FREQUENCY': os.getenv('PIT_SNAPSHOT_FREQUENCY', 'daily'),  # daily, hourly, real-time
    'RETENTION_DAYS': int(os.getenv('PIT_RETENTION_DAYS', '90')),
    'BATCH_SIZE': int(os.getenv('PIT_BATCH_SIZE', '1000')),
    'ENABLE_CORPORATE_ACTIONS': os.getenv('PIT_ENABLE_CORPORATE_ACTIONS', 'True').lower() == 'true',
}

# Institutional Features Configuration
INSTITUTIONAL_CONFIG = {
    'ENABLED': os.getenv('INSTITUTIONAL_FEATURES_ENABLED', 'True').lower() == 'true',
    'REQUIRE_AUTHENTICATION': os.getenv('INSTITUTIONAL_REQUIRE_AUTH', 'True').lower() == 'true',
    'RATE_LIMIT_PER_USER': int(os.getenv('INSTITUTIONAL_RATE_LIMIT', '100')),  # requests per hour
    'ENABLE_AUDIT_TRAIL': os.getenv('INSTITUTIONAL_ENABLE_AUDIT', 'True').lower() == 'true',
    'ENABLE_DRY_RUN': os.getenv('INSTITUTIONAL_ENABLE_DRY_RUN', 'True').lower() == 'true',
    'MAX_UNIVERSE_SIZE': int(os.getenv('INSTITUTIONAL_MAX_UNIVERSE', '2000')),
    'DEFAULT_CONSTRAINTS': {
        'max_weight_per_name': float(os.getenv('INST_MAX_WEIGHT_PER_NAME', '0.10')),
        'max_sector_weight': float(os.getenv('INST_MAX_SECTOR_WEIGHT', '0.30')),
        'max_turnover': float(os.getenv('INST_MAX_TURNOVER', '0.25')),
        'min_liquidity_score': float(os.getenv('INST_MIN_LIQUIDITY', '0.0')),
        'risk_aversion': float(os.getenv('INST_RISK_AVERSION', '5.0')),
        'cost_aversion': float(os.getenv('INST_COST_AVERSION', '1.0')),
        'cvar_confidence': float(os.getenv('INST_CVAR_CONFIDENCE', '0.95')),
        'long_only': os.getenv('INST_LONG_ONLY', 'True').lower() == 'true',
    }
}

# Monitoring Configuration
MONITORING_CONFIG = {
    'ENABLED': os.getenv('MONITORING_ENABLED', 'True').lower() == 'true',
    'LOG_LEVEL': os.getenv('MONITORING_LOG_LEVEL', 'INFO'),
    'ENABLE_METRICS': os.getenv('MONITORING_ENABLE_METRICS', 'True').lower() == 'true',
    'ENABLE_ALERTS': os.getenv('MONITORING_ENABLE_ALERTS', 'True').lower() == 'true',
    'METRICS_RETENTION_DAYS': int(os.getenv('MONITORING_RETENTION_DAYS', '30')),
    'ALERT_EMAIL': os.getenv('MONITORING_ALERT_EMAIL', ''),
    'SLACK_WEBHOOK': os.getenv('MONITORING_SLACK_WEBHOOK', ''),
    'HEALTH_CHECK_INTERVAL': int(os.getenv('MONITORING_HEALTH_CHECK_INTERVAL', '60')),  # seconds
}
# API Configuration - Environment Variables Only
ALPHA_VANTAGE_API_KEY = os.getenv('ALPHA_VANTAGE_API_KEY')  # No default - must be set via environment
FINNHUB_API_KEY = os.getenv('FINNHUB_API_KEY')  # No default - must be set via environment  
NEWS_API_KEY = os.getenv('NEWS_API_KEY')  # No default - must be set via environment
POLYGON_API_KEY = os.getenv('POLYGON_API_KEY')  # No default - must be set via environment

# Use Finnhub and Polygon as primary data sources (60 requests/minute each)
if os.getenv('USE_FINNHUB', 'true').lower() == 'true' and FINNHUB_API_KEY:
    print("INFO: Using Finnhub API for real-time market data (60 requests/minute)")
    print("INFO: Using Polygon API for additional market data")
    # Disable Alpha Vantage completely
    ALPHA_VANTAGE_API_KEY = None
elif os.getenv('DISABLE_ALPHA_VANTAGE', 'true').lower() == 'true':
    ALPHA_VANTAGE_API_KEY = None
    print("INFO: Alpha Vantage API disabled. Using Polygon and Finnhub.")
elif not ALPHA_VANTAGE_API_KEY:
    print("WARNING: No API keys configured. Using mock data.")
# Redis Configuration for Caching
REDIS_HOST = os.getenv('REDIS_HOST', 'localhost')
REDIS_PORT = int(os.getenv('REDIS_PORT', 6379))
REDIS_DB = int(os.getenv('REDIS_DB', 0))
REDIS_PASSWORD = os.getenv('REDIS_PASSWORD', None)
# Cache Configuration - set above based on mode
# Use Redis for session storage as well
SESSION_ENGINE = 'django.contrib.sessions.backends.cache'
SESSION_CACHE_ALIAS = 'default'
# Stock Analysis Configuration
STOCK_ANALYSIS_CONFIG = {
'CACHE_TIMEOUT': {
'QUOTE_DATA': 300, # 5 minutes for real-time quotes
'OVERVIEW_DATA': 3600, # 1 hour for company overview
'HISTORICAL_DATA': 86400, # 24 hours for historical data
'ANALYSIS_RESULT': 1800, # 30 minutes for analysis results
},
'RATE_LIMITS': {
'ALPHA_VANTAGE': {
'REQUESTS_PER_MINUTE': 5,
'REQUESTS_PER_DAY': 500,
'BURST_LIMIT': 10,
}
},
'BATCH_PROCESSING': {
'MAX_STOCKS_PER_BATCH': 10,
'BATCH_DELAY_SECONDS': 2,
'MAX_CONCURRENT_BATCHES': 3,
}
}
# Celery Configuration (Disabled for local development)
CELERY_BROKER_URL = 'memory://'
CELERY_RESULT_BACKEND = 'cache+memory://'
CELERY_ACCEPT_CONTENT = ['json']
CELERY_TASK_SERIALIZER = 'json'
CELERY_RESULT_SERIALIZER = 'json'
CELERY_TIMEZONE = TIME_ZONE
# Celery Beat Schedule
from celery.schedules import crontab

CELERY_BEAT_SCHEDULE = {
'update-stock-data': {
'task': 'core.stock_service.update_stock_data_periodic',
'schedule': 3600.0, # Every hour
},
'cleanup-old-cache': {
'task': 'core.stock_service.cleanup_old_cache',
'schedule': 86400.0, # Every day
},
"prewarm-universe-2am": {
    "task": "core.tasks.prewarm_universe",
    "schedule": crontab(hour=2, minute=0),
    "options": {"queue": "ml_io"},
},
"train-stacking-3am": {
    "task": "core.tasks.train_stacking_model",
    "schedule": crontab(hour=3, minute=0),
    "options": {"queue": "ml_train"},
},
}
# Channels Configuration (Disabled for local development)
CHANNEL_LAYERS = {
'default': {
'BACKEND': 'channels.layers.InMemoryChannelLayer',
},
}

# CORS Configuration (dev only)
CORS_ALLOW_ALL_ORIGINS = True  # dev only

# Authentication backends
AUTHENTICATION_BACKENDS = [
    "graphql_jwt.backends.JSONWebTokenBackend",
    "django.contrib.auth.backends.ModelBackend",
]

# GraphQL Configuration - Single source of truth
GRAPHENE = {
    "SCHEMA": "gql.schema_root.schema",  # <- single source of truth
    # Optional while debugging, remove when done:
    "MIDDLEWARE": ["graphene_django.debug.DjangoDebugMiddleware"],
}

# Temporary logging for GraphQL debugging
LOGGING = {
    "version": 1,
    "disable_existing_loggers": False,
    "handlers": {"console": {"class": "logging.StreamHandler"}},
    "loggers": {
        "graphql": {"handlers": ["console"], "level": "DEBUG"},
        "django.request": {"handlers": ["console"], "level": "ERROR"},
    },
}

# Disable JWT middleware in development to avoid signature decoding errors
DEV_ALLOW_ANON_GRAPHQL = os.getenv("DEV_ALLOW_ANON_GRAPHQL", "1") == "1"

if DEV_ALLOW_ANON_GRAPHQL and DEBUG:
    print("INFO: Development mode - JWT middleware disabled for anonymous GraphQL requests")
else:
    GRAPHENE["MIDDLEWARE"] = ["graphql_jwt.middleware.JSONWebTokenMiddleware"]

# CSRF Configuration for dev and production
CSRF_TRUSTED_ORIGINS = [
    "http://localhost:8000", 
    "http://127.0.0.1:8000",
    "http://riches-reach-alb-1199497064.us-east-1.elb.amazonaws.com"
]

# Environment-driven RPC + AAVE Pool
RPC_SEPOLIA = os.getenv("RPC_SEPOLIA", "https://eth-sepolia.g.alchemy.com/v2/<KEY>")
AAVE_POOL_ADDRESS = os.getenv("AAVE_POOL_ADDRESS", "0x0000000000000000000000000000000000000000")

# Celery Configuration for Real-Time Data Updates
CELERY_BROKER_URL = os.getenv('CELERY_BROKER_URL', 'redis://localhost:6379/0')
CELERY_RESULT_BACKEND = os.getenv('CELERY_RESULT_BACKEND', 'redis://localhost:6379/0')
CELERY_ACCEPT_CONTENT = ['json']
CELERY_TASK_SERIALIZER = 'json'
CELERY_RESULT_SERIALIZER = 'json'
CELERY_TIMEZONE = 'America/New_York'

# Real-Time Data Update Settings
REALTIME_UPDATE_ENABLED = os.getenv('REALTIME_UPDATE_ENABLED', 'True').lower() == 'true'
REALTIME_UPDATE_INTERVAL = int(os.getenv('REALTIME_UPDATE_INTERVAL', '300'))  # 5 minutes
PRIORITY_UPDATE_INTERVAL = int(os.getenv('PRIORITY_UPDATE_INTERVAL', '60'))   # 1 minute

# API Rate Limiting Settings
API_RATE_LIMITS = {
    'ALPHA_VANTAGE': {'limit': 5, 'window': 60},   # 5 requests per minute
    'FINNHUB': {'limit': 60, 'window': 60},        # 60 requests per minute
    'YAHOO_FINANCE': {'limit': 100, 'window': 60}, # 100 requests per minute
}
# Channels Configuration
CHANNEL_LAYERS = {
    'default': {
        'BACKEND': 'channels.layers.InMemoryChannelLayer',  # Use in-memory for simplicity
    },
}

# ASGI Application
ASGI_APPLICATION = 'richesreach.asgi.application'
