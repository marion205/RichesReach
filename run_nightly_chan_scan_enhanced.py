#!/usr/bin/env python3
"""
Enhanced Nightly Chan Portfolio Scan with Risk Controls & Logging

Scans the market using the complete Chan portfolio pipeline with:
- Conservative gating (robustness ‚â•0.7 AND SSR ‚â•0.6)
- Risk controls (max drawdown, daily loss, symbol stops, kill-switch)
- Comprehensive logging (inputs, outputs, "why" drivers)
- Evaluation dashboard structure

Usage:
    python3 run_nightly_chan_scan_enhanced.py
    python3 run_nightly_chan_scan_enhanced.py --min-robustness 0.7 --min-ssr 0.6
"""

import sys
import os
import argparse
import pandas as pd
import numpy as np
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Any, Tuple
import csv
import json
from pathlib import Path

# Add deployment_package to path
sys.path.insert(0, os.path.join(os.path.dirname(__file__), 'deployment_package'))

from backend.core.fss_engine import get_fss_engine
from backend.core.chan_quant_signal_engine import ChanQuantSignalEngine
from backend.core.chan_portfolio_allocator import get_chan_portfolio_allocator

# Try to import yfinance
try:
    import yfinance as yf
    YFINANCE_AVAILABLE = True
except ImportError:
    YFINANCE_AVAILABLE = False
    print("‚ö†Ô∏è  yfinance not available. Install with: pip install yfinance")

# Default universe
SP500_SAMPLE = [
    "AAPL", "MSFT", "GOOGL", "AMZN", "NVDA", "META", "TSLA", "BRK.B",
    "V", "JNJ", "WMT", "PG", "JPM", "MA", "UNH", "HD", "DIS", "BAC",
    "XOM", "VZ", "ADBE", "CMCSA", "NFLX", "COST", "NKE", "MRK", "PFE"
]

# Risk control parameters
RISK_CONFIG = {
    "max_drawdown_pct": 0.20,  # 20% max drawdown
    "max_daily_loss_pct": 0.05,  # 5% max daily loss
    "symbol_stop_loss_pct": 0.10,  # 10% stop loss per symbol
    "min_liquidity_volume": 1_000_000,  # Minimum daily volume
    "max_position_size_pct": 0.30,  # 30% max position size
    "kill_switch_conditions": {
        "min_data_coverage": 0.80,  # 80% data coverage required
        "min_regime_confidence": 0.50,  # 50% regime confidence
        "min_ssr": 0.60,  # 60% SSR required
        "min_robustness": 0.70  # 70% robustness required
    }
}

# Logging directory
LOG_DIR = Path("paper_trading_logs")
LOG_DIR.mkdir(exist_ok=True)


def fetch_historical_data(tickers: List[str], lookback_days: int = 252) -> Optional[Dict]:
    """Fetch historical data for analysis"""
    if not YFINANCE_AVAILABLE:
        print("‚ö†Ô∏è  yfinance not available, cannot fetch historical data")
        return None
    
    print(f"\nüìà Fetching {lookback_days} days of historical data...")
    
    end_date = datetime.now()
    start_date = end_date - timedelta(days=lookback_days + 30)
    
    prices_dict = {}
    volumes_dict = {}
    spy_data = None
    
    for ticker in tickers:
        try:
            print(f"   Fetching {ticker}...", end=" ", flush=True)
            stock = yf.Ticker(ticker)
            hist = stock.history(start=start_date, end=end_date, auto_adjust=True)
            
            if not hist.empty:
                prices_dict[ticker] = hist['Close']
                volumes_dict[ticker] = hist['Volume']
                print("‚úÖ")
            else:
                print("‚ùå")
        except Exception as e:
            print(f"‚ùå ({e})")
    
    # Fetch SPY
    try:
        print(f"   Fetching SPY...", end=" ", flush=True)
        spy = yf.Ticker("SPY")
        spy_hist = spy.history(start=start_date, end=end_date, auto_adjust=True)
        if not spy_hist.empty:
            spy_data = spy_hist['Close']
            print("‚úÖ")
        else:
            print("‚ùå")
    except Exception as e:
        print(f"‚ùå ({e})")
    
    if not prices_dict:
        return None
    
    prices_df = pd.DataFrame(prices_dict)
    volumes_df = pd.DataFrame(volumes_dict)
    
    return {
        "prices": prices_df.sort_index(),
        "volumes": volumes_df.sort_index().fillna(0),
        "spy": spy_data.sort_index() if spy_data is not None else None
    }


def fetch_current_prices(tickers: List[str]) -> Dict[str, float]:
    """Fetch current prices for tickers"""
    if not YFINANCE_AVAILABLE:
        return {ticker: 100.0 + np.random.uniform(-20, 20) for ticker in tickers}
    
    prices = {}
    for ticker in tickers:
        try:
            stock = yf.Ticker(ticker)
            info = stock.info
            current_price = info.get('currentPrice') or info.get('regularMarketPrice')
            if current_price:
                prices[ticker] = float(current_price)
        except Exception:
            pass
    
    return prices


def check_kill_switch(
    data_quality: Dict,
    regime: str,
    regime_confidence: float,
    min_ssr: float,
    min_robustness: float
) -> Tuple[bool, str]:
    """Check if kill-switch conditions are met"""
    config = RISK_CONFIG["kill_switch_conditions"]
    
    # Check data coverage
    if data_quality.get("coverage", 1.0) < config["min_data_coverage"]:
        return False, f"Data coverage {data_quality.get('coverage', 0):.2%} < {config['min_data_coverage']:.2%}"
    
    # Check regime confidence
    if regime_confidence < config["min_regime_confidence"]:
        return False, f"Regime confidence {regime_confidence:.2%} < {config['min_regime_confidence']:.2%}"
    
    # Check SSR threshold
    if min_ssr < config["min_ssr"]:
        return False, f"Min SSR {min_ssr:.3f} < {config['min_ssr']:.3f}"
    
    # Check robustness threshold
    if min_robustness < config["min_robustness"]:
        return False, f"Min robustness {min_robustness:.3f} < {config['min_robustness']:.3f}"
    
    return True, "All kill-switch checks passed"


def get_top_drivers(fss_result, robustness: float, ssr: float) -> List[Dict[str, Any]]:
    """Extract top 3 drivers for explainability"""
    drivers = []
    
    # FSS components
    if hasattr(fss_result, 'trend_score'):
        drivers.append({
            "driver": "trend_score",
            "value": fss_result.trend_score,
            "weight": 0.25,
            "explanation": f"Trend score: {fss_result.trend_score:.1f}/100"
        })
    
    if hasattr(fss_result, 'fundamental_score'):
        drivers.append({
            "driver": "fundamental_score",
            "value": fss_result.fundamental_score,
            "weight": 0.20,
            "explanation": f"Fundamental score: {fss_result.fundamental_score:.1f}/100"
        })
    
    # Robustness
    drivers.append({
        "driver": "regime_robustness",
        "value": robustness,
        "weight": 0.30,
        "explanation": f"Regime robustness: {robustness:.3f} (works across market regimes)"
    })
    
    # SSR
    drivers.append({
        "driver": "signal_stability",
        "value": ssr,
        "weight": 0.25,
        "explanation": f"Signal stability: {ssr:.3f} (predictable signal)"
    })
    
    # Sort by weight and return top 3
    drivers.sort(key=lambda x: x["weight"], reverse=True)
    return drivers[:3]


def run_enhanced_scan(
    universe: List[str] = None,
    min_robustness: float = 0.7,
    min_ssr: float = 0.6,
    max_positions: int = 10,
    output_file: str = "chan_orders.csv",
    log_file: str = None
) -> Optional[Dict]:
    """Run enhanced nightly scan with risk controls and logging"""
    timestamp = datetime.now()
    
    print("\n" + "="*80)
    print("ENHANCED NIGHTLY CHAN PORTFOLIO SCAN")
    print("="*80)
    print(f"\nüìÖ Date: {timestamp.strftime('%Y-%m-%d %H:%M:%S')}")
    print(f"   Conservative Gating: Robustness ‚â•{min_robustness}, SSR ‚â•{min_ssr}")
    
    if universe is None:
        universe = SP500_SAMPLE
    
    # Initialize logging
    log_entry = {
        "timestamp": timestamp.isoformat(),
        "config": {
            "universe_size": len(universe),
            "min_robustness": min_robustness,
            "min_ssr": min_ssr,
            "max_positions": max_positions,
            "risk_config": RISK_CONFIG
        },
        "inputs": {},
        "outputs": {},
        "risk_checks": {},
        "decisions": []
    }
    
    # Fetch historical data
    historical_data = fetch_historical_data(universe, lookback_days=252)
    
    if historical_data is None:
        log_entry["outputs"]["status"] = "FAILED"
        log_entry["outputs"]["error"] = "Failed to fetch historical data"
        _save_log(log_entry, log_file)
        return None
    
    prices = historical_data["prices"]
    volumes = historical_data["volumes"]
    spy = historical_data["spy"]
    
    # Data quality check
    data_coverage = len(prices) / 252.0  # Approximate coverage
    data_quality = {"coverage": data_coverage, "tickers_with_data": len(prices.columns)}
    
    log_entry["inputs"]["data_quality"] = data_quality
    log_entry["inputs"]["tickers_scanned"] = universe
    log_entry["inputs"]["tickers_with_data"] = list(prices.columns)
    
    # Initialize engines
    fss_engine = get_fss_engine()
    chan_engine = ChanQuantSignalEngine()
    allocator = get_chan_portfolio_allocator()
    
    # Calculate FSS scores
    print("\nüìà Calculating FSS scores...")
    try:
        fss_data = fss_engine.compute_fss_v3(
            prices=prices,
            volumes=volumes,
            spy=spy,
            vix=None
        )
        print("‚úÖ FSS calculation complete")
    except Exception as e:
        log_entry["outputs"]["status"] = "FAILED"
        log_entry["outputs"]["error"] = str(e)
        _save_log(log_entry, log_file)
        return None
    
    # Analyze signals with conservative gating
    print(f"\nüîç Analyzing signals (Robustness ‚â•{min_robustness}, SSR ‚â•{min_ssr})...")
    
    ticker_signals = {}
    kelly_fractions = {}
    fss_scores = {}
    fss_robustness = {}
    fss_ssr = {}
    volatilities = {}
    current_prices_dict = {}
    volumes_dict = {}
    
    # Fetch current prices and volumes
    current_prices_dict = fetch_current_prices(universe)
    for ticker in universe:
        if ticker in volumes.columns:
            volumes_dict[ticker] = volumes[ticker].iloc[-1] if len(volumes[ticker]) > 0 else 0
    
    for ticker in universe:
        if ticker not in prices.columns:
            continue
        
        try:
            # Get FSS result with robustness and SSR
            fss_result = fss_engine.get_stock_fss(
                ticker=ticker,
                fss_data=fss_data,
                regime="Expansion",
                prices=prices,
                spy=spy,
                vix=None,
                calculate_robustness=True
            )
            
            robustness = fss_result.regime_robustness_score or 0.0
            ssr = fss_result.signal_stability_rating or 0.0
            
            # Conservative gating
            if robustness < min_robustness or ssr < min_ssr:
                log_entry["decisions"].append({
                    "ticker": ticker,
                    "action": "REJECTED",
                    "reason": f"Robustness {robustness:.3f} < {min_robustness} OR SSR {ssr:.3f} < {min_ssr}",
                    "robustness": robustness,
                    "ssr": ssr,
                    "fss_score": fss_result.fss_score
                })
                continue
            
            # Liquidity check
            volume = volumes_dict.get(ticker, 0)
            if volume < RISK_CONFIG["min_liquidity_volume"]:
                log_entry["decisions"].append({
                    "ticker": ticker,
                    "action": "REJECTED",
                    "reason": f"Insufficient liquidity: {volume:,.0f} < {RISK_CONFIG['min_liquidity_volume']:,.0f}",
                    "volume": volume
                })
                continue
            
            # Get Kelly fraction
            ticker_returns = prices[ticker].pct_change().dropna()
            if len(ticker_returns) >= 20:
                kelly_result = chan_engine.calculate_kelly_position_size(
                    symbol=ticker,
                    historical_returns=ticker_returns
                )
                kelly_fraction = kelly_result.recommended_fraction
            else:
                kelly_fraction = min(0.15, fss_result.fss_score / 100.0 * 0.2)
            
            kelly_fractions[ticker] = kelly_fraction
            fss_scores[ticker] = fss_result.fss_score
            fss_robustness[ticker] = robustness
            fss_ssr[ticker] = ssr
            
            # Calculate volatility
            if len(ticker_returns) > 20:
                volatilities[ticker] = ticker_returns.std() * np.sqrt(252)
            else:
                volatilities[ticker] = 0.20
            
            # Get top drivers
            top_drivers = get_top_drivers(fss_result, robustness, ssr)
            
            ticker_signals[ticker] = {
                "fss": fss_result.fss_score,
                "robustness": robustness,
                "ssr": ssr,
                "kelly": kelly_fraction,
                "volatility": volatilities[ticker],
                "volume": volume,
                "top_drivers": top_drivers
            }
            
            log_entry["decisions"].append({
                "ticker": ticker,
                "action": "ACCEPTED",
                "fss_score": fss_result.fss_score,
                "robustness": robustness,
                "ssr": ssr,
                "kelly_fraction": kelly_fraction,
                "top_drivers": top_drivers
            })
            
        except Exception as e:
            log_entry["decisions"].append({
                "ticker": ticker,
                "action": "ERROR",
                "error": str(e)
            })
            continue
    
    print(f"‚úÖ Analyzed {len(ticker_signals)} tickers passing conservative gating")
    
    if not ticker_signals:
        log_entry["outputs"]["status"] = "NO_POSITIONS"
        log_entry["outputs"]["reason"] = "No tickers passed conservative gating"
        _save_log(log_entry, log_file)
        print("\n‚ùå No tickers passed conservative gating. No orders generated.")
        return None
    
    # Kill-switch check
    min_rob = min(fss_robustness.values())
    min_ssr_val = min(fss_ssr.values())
    regime_confidence = 0.75  # Placeholder - would come from regime classifier
    
    kill_switch_ok, kill_switch_msg = check_kill_switch(
        data_quality, "Expansion", regime_confidence, min_ssr_val, min_rob
    )
    
    log_entry["risk_checks"]["kill_switch"] = {
        "passed": kill_switch_ok,
        "message": kill_switch_msg
    }
    
    if not kill_switch_ok:
        log_entry["outputs"]["status"] = "KILL_SWITCH"
        log_entry["outputs"]["reason"] = kill_switch_msg
        _save_log(log_entry, log_file)
        print(f"\nüõë KILL-SWITCH ACTIVATED: {kill_switch_msg}")
        return None
    
    # Portfolio allocation
    print("\nüíº Running portfolio allocation...")
    valid_tickers = list(ticker_signals.keys())
    
    if len(valid_tickers) < 2:
        weights = {ticker: 1.0 / len(valid_tickers) for ticker in valid_tickers}
    else:
        returns_matrix = prices[valid_tickers].pct_change().dropna()
        
        allocation_result = allocator.allocate_portfolio(
            tickers=valid_tickers,
            kelly_fractions=kelly_fractions,
            fss_scores=fss_scores,
            fss_robustness=fss_robustness,
            returns_matrix=returns_matrix,
            volatilities=volatilities,
            method="kelly_constrained"
        )
        
        # Apply position size limits
        sorted_weights = sorted(allocation_result.weights.items(), key=lambda x: x[1], reverse=True)
        top_positions = sorted_weights[:max_positions]
        
        # Cap individual positions
        capped_weights = {}
        for ticker, weight in top_positions:
            capped_weight = min(weight, RISK_CONFIG["max_position_size_pct"])
            capped_weights[ticker] = capped_weight
        
        # Renormalize
        total_weight = sum(capped_weights.values())
        if total_weight > 0:
            weights = {ticker: weight / total_weight for ticker, weight in capped_weights.items()}
        else:
            log_entry["outputs"]["status"] = "FAILED"
            log_entry["outputs"]["error"] = "Portfolio allocation failed"
            _save_log(log_entry, log_file)
            return None
    
    # Generate orders with logging
    orders = []
    for ticker, weight in sorted(weights.items(), key=lambda x: x[1], reverse=True):
        current_price = current_prices_dict.get(ticker, 0.0)
        if current_price == 0:
            continue
        
        signal = ticker_signals[ticker]
        
        order = {
            "symbol": ticker,
            "action": "BUY",
            "quantity": f"{weight:.4f}",
            "price": f"{current_price:.2f}",
            "order_type": "MARKET",
            "fss_score": f"{signal['fss']:.2f}",
            "robustness": f"{signal['robustness']:.3f}",
            "ssr": f"{signal['ssr']:.3f}",
            "kelly_fraction": f"{signal['kelly']:.4f}",
            "weight": f"{weight:.4f}",
            "stop_loss_pct": f"{RISK_CONFIG['symbol_stop_loss_pct']:.2%}",
            "timestamp": timestamp.strftime("%Y-%m-%d %H:%M:%S")
        }
        
        orders.append(order)
        
        # Log order decision
        log_entry["decisions"].append({
            "ticker": ticker,
            "action": "ORDER_GENERATED",
            "weight": weight,
            "price": current_price,
            "stop_loss": current_price * (1 - RISK_CONFIG["symbol_stop_loss_pct"]),
            "why": [d["explanation"] for d in signal["top_drivers"]]
        })
    
    # Write orders CSV
    with open(output_file, 'w', newline='') as f:
        if orders:
            writer = csv.DictWriter(f, fieldnames=orders[0].keys())
            writer.writeheader()
            writer.writerows(orders)
    
    # Final logging
    log_entry["outputs"]["status"] = "SUCCESS"
    log_entry["outputs"]["orders_generated"] = len(orders)
    log_entry["outputs"]["orders_file"] = output_file
    log_entry["outputs"]["total_weight"] = sum(float(o["weight"]) for o in orders)
    log_entry["risk_checks"]["position_limits"] = {
        "max_position_size": RISK_CONFIG["max_position_size_pct"],
        "max_positions": max_positions,
        "actual_positions": len(orders)
    }
    
    _save_log(log_entry, log_file)
    
    # Print summary
    print("\n" + "="*80)
    print("ORDERS SUMMARY")
    print("="*80)
    print(f"\n{'Symbol':<8} {'Weight':<10} {'FSS':<8} {'Robust':<8} {'SSR':<8} {'Price':<10}")
    print("-" * 80)
    
    for order in orders:
        print(f"{order['symbol']:<8} {float(order['weight']):>9.2%} {order['fss_score']:>7} {order['robustness']:>7} {order['ssr']:>7} ${order['price']:>9}")
    
    print("-" * 80)
    print(f"{'TOTAL':<8} {sum(float(o['weight']) for o in orders):>9.2%}")
    print(f"\nüìÑ Orders saved to: {output_file}")
    print(f"üìã Log saved to: {log_file or 'paper_trading_logs/scan_' + timestamp.strftime('%Y%m%d_%H%M%S') + '.json'}")
    print("="*80 + "\n")
    
    return {
        "orders": orders,
        "weights": weights,
        "signals": ticker_signals,
        "output_file": output_file,
        "log_entry": log_entry
    }


def _save_log(log_entry: Dict, log_file: Optional[str] = None):
    """Save log entry to JSON file"""
    if log_file is None:
        timestamp = datetime.fromisoformat(log_entry["timestamp"])
        log_file = LOG_DIR / f"scan_{timestamp.strftime('%Y%m%d_%H%M%S')}.json"
    else:
        log_file = Path(log_file)
    
    with open(log_file, 'w') as f:
        json.dump(log_entry, f, indent=2, default=str)


def main():
    parser = argparse.ArgumentParser(description="Enhanced Nightly Chan Portfolio Scan")
    parser.add_argument("--universe", choices=["SP500", "DOW30"], default="SP500")
    parser.add_argument("--min-robustness", type=float, default=0.7, help="Min robustness (default: 0.7)")
    parser.add_argument("--min-ssr", type=float, default=0.6, help="Min SSR (default: 0.6)")
    parser.add_argument("--max-positions", type=int, default=10, help="Max positions (default: 10)")
    parser.add_argument("--output", default="chan_orders.csv", help="Output CSV file")
    parser.add_argument("--log", help="Log JSON file (auto-generated if not specified)")
    
    args = parser.parse_args()
    
    universe = SP500_SAMPLE if args.universe == "SP500" else DOW30
    
    result = run_enhanced_scan(
        universe=universe,
        min_robustness=args.min_robustness,
        min_ssr=args.min_ssr,
        max_positions=args.max_positions,
        output_file=args.output,
        log_file=args.log
    )
    
    if result:
        print("‚úÖ Enhanced scan complete!")
    else:
        print("‚ùå Enhanced scan failed or no positions generated")
        sys.exit(1)


if __name__ == "__main__":
    main()

