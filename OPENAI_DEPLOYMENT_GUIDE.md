# üöÄ OpenAI Production Deployment Guide

## ‚úÖ **Current Status: Production-Ready**

Your system now has **bulletproof OpenAI integration** with:
- ‚úÖ **Feature flags** for safe rollout
- ‚úÖ **Environment separation** (staging/prod API keys)
- ‚úÖ **Automatic fallback** to mock data
- ‚úÖ **Timeout protection** (12-second limit)
- ‚úÖ **Usage monitoring** and logging
- ‚úÖ **Client-side feature detection**

## üéØ **Deployment Steps**

### **Step 1: Create OpenAI API Keys**

1. **Go to [OpenAI Platform](https://platform.openai.com/)**
2. **Create two separate API keys:**
   - `OPENAI_API_KEY_STAGING` - for testing
   - `OPENAI_API_KEY_PROD` - for production
3. **Add billing to each account:**
   - Start with $10-25 prepay
   - Set monthly limit: $50
   - Set daily limit: $10
   - Enable email alerts

### **Step 2: Configure Staging Environment**

```bash
# Set environment variables for staging
export USE_OPENAI=true
export OPENAI_API_KEY_STAGING=sk-your-staging-key-here
export OPENAI_MODEL=gpt-4o-mini
export OPENAI_MAX_TOKENS=1200
export OPENAI_TIMEOUT_MS=12000
export OPENAI_ENABLE_FALLBACK=true
export DEBUG=true
```

### **Step 3: Test Staging**

```bash
# Test AI status endpoint
curl -X GET http://your-staging-server:8000/api/ai-status
# Expected: {"ai_enabled": true, "model": "gpt-4o-mini", ...}

# Test AI recommendations
curl -X POST http://your-staging-server:8000/api/ai-options/recommendations \
  -H "Content-Type: application/json" \
  -d '{"symbol":"AAPL","portfolio_value":10000,"time_horizon":30,"user_risk_tolerance":"medium"}'
# Expected: Real AI recommendations with "AI recommendations generated successfully using OpenAI"
```

### **Step 4: Monitor Staging Usage**

- **Watch OpenAI dashboard** for token usage
- **Check server logs** for fallback triggers
- **Monitor response times** and error rates
- **Run load tests** with realistic traffic

### **Step 5: Deploy to Production**

```bash
# Set environment variables for production
export USE_OPENAI=true
export OPENAI_API_KEY_PROD=sk-your-production-key-here
export OPENAI_MODEL=gpt-4o-mini
export OPENAI_MAX_TOKENS=1200
export OPENAI_TIMEOUT_MS=12000
export OPENAI_ENABLE_FALLBACK=true
export DEBUG=false
```

## üîß **Configuration Options**

### **Environment Variables**

| Variable | Default | Description |
|----------|---------|-------------|
| `USE_OPENAI` | `false` | Master feature flag |
| `OPENAI_API_KEY_STAGING` | - | Staging API key |
| `OPENAI_API_KEY_PROD` | - | Production API key |
| `OPENAI_MODEL` | `gpt-4o-mini` | Model to use |
| `OPENAI_MAX_TOKENS` | `1200` | Max tokens per request |
| `OPENAI_TIMEOUT_MS` | `12000` | Request timeout (ms) |
| `OPENAI_ENABLE_FALLBACK` | `true` | Enable fallback to mock |

### **Model Recommendations**

| Model | Cost | Quality | Use Case |
|-------|------|---------|----------|
| `gpt-4o-mini` | $0.15/1M tokens | High | **Recommended** |
| `gpt-3.5-turbo` | $0.50/1M tokens | Good | Fallback |
| `gpt-4o` | $5.00/1M tokens | Excellent | Premium tier |

## üìä **Monitoring & Alerts**

### **Server Logs to Watch**

```bash
# Success with OpenAI
DEBUG: Successfully used model: gpt-4o-mini
DEBUG: Successfully generated real AI recommendations

# Fallback scenarios
DEBUG: OpenAI quota/limit error: ..., using fallback recommendations
DEBUG: OpenAI timeout error: ..., using fallback recommendations
DEBUG: OpenAI disabled via USE_OPENAI flag, using fallback recommendations
```

### **API Status Endpoint**

```bash
# Check AI status
curl -X GET http://your-server:8000/api/ai-status

# Response examples:
# AI Enabled: {"ai_enabled": true, "model": "gpt-4o-mini", "fallback_enabled": true}
# AI Disabled: {"ai_enabled": false, "model": null, "fallback_enabled": true}
```

### **Cost Monitoring**

- **Set up OpenAI dashboard alerts**
- **Monitor daily/monthly usage**
- **Track cost per request**
- **Set hard limits to prevent bill shock**

## üõ°Ô∏è **Safety Features**

### **Automatic Fallback**

Your system automatically falls back to mock data when:
- ‚úÖ OpenAI API is down
- ‚úÖ Quota exceeded
- ‚úÖ Request timeout
- ‚úÖ Invalid API key
- ‚úÖ Model not available
- ‚úÖ Network issues

### **Graceful Degradation**

- **App continues working** even if OpenAI fails
- **Users get recommendations** (mock data)
- **No error messages** shown to users
- **Logs show which path was used**

### **Feature Flag Control**

```bash
# Disable AI instantly (emergency)
export USE_OPENAI=false
# Restart server - all requests use mock data

# Re-enable AI
export USE_OPENAI=true
# Restart server - AI requests resume
```

## üì± **Client-Side Integration**

### **React Native Feature Detection**

```typescript
import { isAIEnabled, getAIStatusText, getAIStatusColor } from '../config/featureFlags';

// Check if AI is enabled
const aiEnabled = await isAIEnabled();

// Show status badge
const statusText = getAIStatusText(aiEnabled); // "AI Powered" or "Mock Data"
const statusColor = getAIStatusColor(aiEnabled); // Green or Orange
```

### **UI Status Badge**

```typescript
// Show AI status in your app
<View style={{ backgroundColor: statusColor }}>
  <Text>{statusText}</Text>
</View>
```

## üö® **Emergency Procedures**

### **If OpenAI Goes Down**

1. **No action needed** - system automatically falls back
2. **Monitor logs** for fallback triggers
3. **Check OpenAI status** at status.openai.com
4. **Re-enable when fixed** (automatic on next request)

### **If Costs Spike**

1. **Set USE_OPENAI=false** immediately
2. **Check OpenAI dashboard** for usage
3. **Review logs** for unusual patterns
4. **Adjust limits** and re-enable

### **If Quality Issues**

1. **Switch model** via OPENAI_MODEL
2. **Adjust prompts** in schema.py
3. **Test in staging** first
4. **Deploy when satisfied**

## ‚úÖ **Verification Checklist**

Before going live:

- [ ] **Staging tested** with real OpenAI API
- [ ] **Usage monitored** for 24+ hours
- [ ] **Costs calculated** and limits set
- [ ] **Fallback tested** (disable API key)
- [ ] **Client-side detection** working
- [ ] **Monitoring alerts** configured
- [ ] **Emergency procedures** documented
- [ ] **Team trained** on feature flags

## üéâ **You're Ready!**

Your system is now **production-ready** with:
- **Zero-downtime deployment** capability
- **Automatic fallback** protection
- **Cost control** and monitoring
- **Feature flag** control
- **Environment separation**

**Deploy with confidence!** üöÄ
